# Resumen de Reentrenamiento del Modelo LSTM

## üîç Diagn√≥stico del Problema

### Problema Identificado
El modelo anterior mostraba **"naive forecasting"** - las predicciones simplemente copiaban el precio actual con ajustes m√≠nimos, resultando en un lag visual de 12h.

### M√©tricas del Modelo Anterior (v1)
```
MAE: $1,242 (solo 3% mejor que persistence forecast $1,280)
Directional Accuracy: 54.8% (apenas mejor que 50% random)
Variance Ratio: 0.15 (predicciones 6.7x m√°s conservadoras que realidad)
Correlation: 0.226 (muy baja)
```

### Causa Ra√≠z: **DATA LEAKAGE**

**Features problem√°ticas (17 eliminadas):**
1. `log_close` - Precio absoluto ‚Üí modelo memoriza P_t
2. `sma_5`, `sma_20`, `sma_50` - Moving averages absolutas
3. `ema_5`, `ema_20`, `ema_50` - Exponential moving averages absolutas
4. `bb_m`, `bb_up`, `bb_dn` - Bandas de Bollinger absolutas
5. `fib_r_*`, `fibext_*` (8 features) - Niveles Fibonacci absolutos

**Correlaci√≥n con close:** >0.99 para todas las features de precio absoluto

---

## ‚úÖ Soluci√≥n Implementada

### 1. **Nuevas Features Limpias** (`add_technical_features_v2()`)

**14 features sin data leakage:**

```python
# Returns (hist√≥ricos, v√°lidos)
- log_ret_1, log_ret_5
- momentum_10  # NEW: tasa de cambio 10 per√≠odos
- log_ret_accel  # NEW: aceleraci√≥n de returns

# Ratios normalizados (no absolutos)
- ma_ratio_20  # NEW: (close - sma_20) / sma_20
- bb_width  # ancho de Bollinger normalizado
- bb_std_pct  # NEW: std normalizado por precio

# Indicadores t√©cnicos (scale-independent)
- rsi_14
- atr_pct  # NEW: ATR normalizado por close
- raw_vol_10, raw_vol_30

# Fibonacci composite (reemplaza 8 features individuales)
- fib_composite  # NEW: ponderado con inverse distance weighting

# TD Sequential
- td_buy_setup, td_sell_setup
```

**Caracter√≠sticas clave:**
- ‚úÖ Sin informaci√≥n de precio absoluto
- ‚úÖ Solo ratios, returns, y distancias normalizadas
- ‚úÖ Fibonacci composite con ponderaci√≥n inteligente
- ‚úÖ Reducci√≥n de 39 ‚Üí 14 features (m√°s eficiente)

### 2. **Funci√≥n de P√©rdida Mejorada** (`combined_loss()`)

```python
total_loss = MSE_return
           + 0.5 * MSE_volatility
           + 0.3 * directional_loss  # NEW: penaliza direcci√≥n incorrecta
           + 0.2 * variance_loss      # NEW: fuerza predicciones con varianza realista
```

**Componentes:**
- `directional_accuracy_loss`: Penaliza predicciones con signo incorrecto
- `variance_matching_loss`: Previene "hedging" (predicciones demasiado conservadoras)

### 3. **Arquitectura Mejorada**

```python
# Antes (v1)
LSTM2Head(input_size=39, hidden=92, layers=2, dropout=0.1)

# Ahora (v2)
LSTM2Head(input_size=14, hidden=128, layers=3, dropout=0.2)
```

**Cambios:**
- ‚úÖ Hidden size: 92 ‚Üí 128 (+39% capacidad)
- ‚úÖ Layers: 2 ‚Üí 3 (+50% profundidad)
- ‚úÖ Dropout: 0.1 ‚Üí 0.2 (mejor regularizaci√≥n)
- ‚úÖ Features: 39 ‚Üí 14 (m√°s limpias, menos ruido)

### 4. **Script de Reentrenamiento** (`retrain_clean_features.py`)

**Caracter√≠sticas:**
- Cosine annealing learning rate scheduler
- Early stopping based on directional accuracy (no solo loss)
- Tracking de m√©tricas adicionales (dir_acc, var_ratio, corr)
- Temporal split (sin shuffling) para validaci√≥n realista
- Guarda historial de entrenamiento en CSV

**Uso:**
```bash
python retrain_clean_features.py \
  --epochs 100 \
  --lr 0.001 \
  --batch-size 256 \
  --hidden 128 \
  --layers 3 \
  --use-combined-loss
```

---

## üéØ M√©tricas Objetivo (v2)

| M√©trica | v1 (Actual) | Target v2 | Mejora |
|---------|------------|-----------|---------|
| MAE improvement vs persistence | 3% | >15% | 5x |
| Directional Accuracy | 54.8% | >60% | +5.2 pts |
| Variance Ratio | 0.15 | >0.5 | 3.3x |
| Correlation | 0.226 | >0.5 | 2.2x |

---

## üìÅ Archivos Modificados/Creados

### Modificados:
1. **`fiboevo.py`**
   - L√≠nea 569-727: `add_technical_features_v2()` agregada
   - L√≠nea 874-971: Loss functions mejoradas agregadas
   - No se modific√≥ c√≥digo existente (backward compatible)

### Creados:
2. **`retrain_clean_features.py`** (675 l√≠neas)
   - Script completo de reentrenamiento
   - Usa features v2 y combined_loss
   - Tracking mejorado de m√©tricas

3. **`diagnose_model.py`** (450 l√≠neas)
   - Herramienta de diagn√≥stico
   - Identifica data leakage
   - Compara con persistence baseline
   - Genera plots de an√°lisis

4. **`RETRAINING_SUMMARY.md`** (este archivo)
   - Documentaci√≥n completa
   - Gu√≠a de uso

### Directorios:
5. **`artifacts_v2/`** (se crear√° al entrenar)
   - `model_best.pt` - Modelo reentrenado
   - `meta.json` - Metadata con 14 features limpias
   - `scaler.pkl` - Scaler entrenado solo con training data
   - `training_history.csv` - Historial de m√©tricas por √©poca

---

## üöÄ C√≥mo Usar

### Paso 1: Verificar Features Actuales
```bash
python diagnose_model.py
```
Esto muestra:
- Data leakage en v1
- Baseline metrics
- Distribuci√≥n de predicciones vs realidad

### Paso 2: Reentrenar con Features Limpias
```bash
# Training b√°sico (100 epochs)
python retrain_clean_features.py --epochs 100

# Training extendido con custom params
python retrain_clean_features.py \
  --epochs 200 \
  --lr 0.0005 \
  --batch-size 512 \
  --hidden 256 \
  --patience 20
```

### Paso 3: Evaluar Nuevo Modelo
```bash
# Usar multi_horizon_inference con artifacts_v2
python example_multi_horizon.py \
  --model artifacts_v2/model_best.pt \
  --meta artifacts_v2/meta.json \
  --scaler artifacts_v2/scaler.pkl
```

### Paso 4: Comparar v1 vs v2
```python
# Ver training history
import pandas as pd
history = pd.read_csv("artifacts_v2/training_history.csv")
print(history.tail())

# Comparar m√©tricas finales
print(f"Final val dir_acc: {history['val_dir_acc'].iloc[-1]:.2f}%")
print(f"Final val corr: {history['val_corr'].iloc[-1]:.4f}")
```

---

## üìä Monitoreo Durante Entrenamiento

El script muestra cada 10 epochs:
```
Epoch 10/100
  Train Loss: 0.000425 | Val Loss: 0.000512
  Train Dir Acc: 58.2% | Val Dir Acc: 56.8%
  Train Var Ratio: 0.4523 | Val Var Ratio: 0.4198
  Train Corr: 0.4872 | Val Corr: 0.4534
  ‚Üí Best model saved (dir_acc=56.8%)
```

**Se√±ales de √©xito:**
- ‚úÖ Dir Acc increasing hacia >60%
- ‚úÖ Var Ratio increasing hacia >0.5
- ‚úÖ Corr increasing hacia >0.5
- ‚úÖ Train/Val no divergen demasiado (no overfitting)

**Se√±ales de problemas:**
- ‚ùå Dir Acc stuck around 50-52% ‚Üí model not learning patterns
- ‚ùå Var Ratio stuck around 0.1-0.2 ‚Üí still hedging
- ‚ùå Corr stuck around 0.2 ‚Üí predictions not correlating
- ‚ùå Train/Val diverging ‚Üí overfitting (increase dropout)

---

## üîß Troubleshooting

### Problema 1: Training muy lento
**Soluci√≥n:** Reducir batch size o usar GPU
```bash
python retrain_clean_features.py --batch-size 128
```

### Problema 2: Overfitting (train/val diverge)
**Soluci√≥n:** Aumentar dropout o reducir hidden size
```bash
python retrain_clean_features.py --dropout 0.3 --hidden 96
```

### Problema 3: Underfitting (m√©tricas no mejoran)
**Soluci√≥n:** Aumentar capacity o epochs
```bash
python retrain_clean_features.py --hidden 256 --layers 4 --epochs 200
```

### Problema 4: Features v2 no se computan correctamente
**Soluci√≥n:** Verificar que add_technical_features_v2() funciona:
```python
from fiboevo import add_technical_features_v2
import numpy as np

# Test con datos sint√©ticos
close = np.random.randn(1000).cumsum() + 100
df = add_technical_features_v2(close)
print(df.columns)  # Debe tener 14 features
print(df.isnull().sum())  # Verificar NaNs
```

---

## üìà Pr√≥ximos Pasos Opcionales

### 1. Multi-Horizon Architecture
Implementar h=12 cabezas separadas para predicciones densas:
```python
class LSTM12Head(nn.Module):
    def __init__(self, input_size, hidden_size):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, ...)
        self.heads = nn.ModuleList([
            nn.Linear(hidden_size, 2)  # (ret, vol) para cada horizonte
            for _ in range(12)
        ])
```

### 2. Attention Mechanism
Agregar attention para que el modelo aprenda qu√© timesteps son m√°s relevantes:
```python
class LSTM2HeadWithAttention(nn.Module):
    ...
    self.attention = nn.MultiheadAttention(hidden_size, num_heads=4)
```

### 3. Ensemble de Modelos
Entrenar m√∫ltiples modelos con seeds diferentes y promediar predicciones:
```bash
for seed in 42 43 44 45 46; do
    python retrain_clean_features.py --seed $seed --output-dir artifacts_v2_seed_$seed
done
```

### 4. Data Augmentation
Entrenar con m√∫ltiples s√≠mbolos o timeframes:
- BTCUSDT 1h + ETHUSDT 1h
- BTCUSDT 1h + BTCUSDT 4h resampled

---

## üìù Checklist de Validaci√≥n

Antes de usar el modelo v2 en producci√≥n:

- [ ] Dir Acc >60% en validation
- [ ] Var Ratio >0.5 (predicciones con varianza realista)
- [ ] Corr >0.5 (predicciones correlacionadas con realidad)
- [ ] MAE improvement >15% vs persistence
- [ ] No divergencia train/val (no overfitting)
- [ ] Plots muestran predicciones alineadas con realidad
- [ ] Backtesting en per√≠odo out-of-sample
- [ ] Stable performance en diferentes market regimes

---

## üéì Lecciones Aprendidas

1. **Data leakage es sutil:** Features con correlaci√≥n >0.95 con target son red flags
2. **Directional accuracy importa m√°s que MSE:** Predecir direcci√≥n correcta > magnitud exacta
3. **Variance matching previene hedging:** Modelo debe ser "valiente" con predicciones
4. **Loss function es cr√≠tica:** MSE solo no es suficiente para time series
5. **Temporal split es esencial:** Random split leak informaci√≥n del futuro
6. **Feature engineering > model complexity:** 14 features limpias > 39 con leakage
7. **Monitor m√∫ltiples m√©tricas:** No confiar solo en loss, ver dir_acc, corr, var_ratio

---

## üìö Referencias

- Diagn√≥stico completo: `model_diagnostics.png`
- C√≥digo de features: `fiboevo.py` l√≠nea 569-727
- C√≥digo de loss: `fiboevo.py` l√≠nea 874-971
- Script de entrenamiento: `retrain_clean_features.py`
- Herramienta de diagn√≥stico: `diagnose_model.py`

---

**Autor:** Claude (Anthropic)
**Fecha:** 2025-10-15
**Versi√≥n:** 2.0
